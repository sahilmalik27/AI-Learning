# AI Learning Journey - 6 Month Research-Focused Program

A comprehensive 6-month research-focused learning program covering mathematical foundations, neural networks, transformers, generative models, reinforcement learning, and cutting-edge AI research topics.

## üöÄ Getting Started

### Prerequisites
- Python 3.13+
- Git
- Virtual environment support

### Setup
```bash
# Clone the repository
git clone <your-repo-url>
cd AI-Learning

# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start Jupyter Lab
jupyter lab
```

## üìö Learning Roadmap

### Month 1: Mathematical Foundations & Basic ML
**Weeks 1-4: Mathematical Foundations**

#### Week 1: Linear Algebra & Calculus
- **Topics**: Vectors, matrices, eigenvalues, derivatives, gradients
- **Projects**: 
  - Matrix operations from scratch
  - Gradient descent implementation
- **Resources**: Create `linear_algebra/` package as you work through the material
- **Key Libraries**: NumPy, SciPy

#### Week 2: Probability & Statistics
- **Topics**: Probability distributions, Bayes' theorem, hypothesis testing
- **Projects**:
  - Monte Carlo simulations
  - Statistical analysis of real datasets
- **Resources**: Create `probability_stats/` package as you work through the material

#### Week 3: Optimization Theory
- **Topics**: Convex optimization, gradient methods, constraints
- **Projects**:
  - Implement various optimization algorithms
  - Solve real optimization problems
- **Resources**: Create `optimization/` package as you work through the material

#### Week 4: Basic Machine Learning
- **Topics**: Linear regression, logistic regression, decision trees
- **Projects**:
  - Build ML pipeline from scratch
  - Compare different algorithms
- **Resources**: Create `basic_ml/` package as you work through the material
- **Key Libraries**: Scikit-learn, Pandas

### Month 2: Deep Learning Fundamentals
**Weeks 5-8: Neural Networks & Deep Learning**

#### Week 5: Neural Network Basics
- **Topics**: Perceptrons, backpropagation, activation functions
- **Projects**:
  - Build neural network from scratch
  - Implement backpropagation algorithm
- **Resources**: Create `neural_networks/` package as you work through the material
- **Key Libraries**: PyTorch, TensorFlow

#### Week 6: Convolutional Neural Networks (CNNs)
- **Topics**: Convolutions, pooling, CNN architectures
- **Projects**:
  - Image classification with CNNs
  - Transfer learning experiments
- **Resources**: Create `cnn/` package as you work through the material

#### Week 7: Recurrent Neural Networks (RNNs)
- **Topics**: LSTM, GRU, sequence modeling
- **Projects**:
  - Text generation with RNNs
  - Time series prediction
- **Resources**: Create `rnn/` package as you work through the material

#### Week 8: Advanced Deep Learning
- **Topics**: Regularization, optimization, advanced architectures
- **Projects**:
  - Implement advanced techniques
  - Hyperparameter tuning
- **Resources**: Create `advanced_dl/` package as you work through the material

### Month 3: Computer Vision & NLP
**Weeks 9-12: Specialized Applications**

#### Week 9: Advanced Computer Vision
- **Topics**: Object detection, segmentation, GANs
- **Projects**:
  - YOLO implementation
  - Image generation with GANs
- **Resources**: Create `computer_vision/` package as you work through the material
- **Key Libraries**: OpenCV, Albumentations

#### Week 10: Natural Language Processing
- **Topics**: Word embeddings, text preprocessing, sentiment analysis
- **Projects**:
  - Build NLP pipeline
  - Sentiment analysis system
- **Resources**: Create `nlp/` package as you work through the material
- **Key Libraries**: NLTK, spaCy

#### Week 11: Attention Mechanisms
- **Topics**: Attention, self-attention, transformer architecture
- **Projects**:
  - Implement attention from scratch
  - Build simple transformer
- **Resources**: Create `attention/` package as you work through the material

#### Week 12: Transformers & BERT
- **Topics**: Transformer architecture, BERT, fine-tuning
- **Projects**:
  - Fine-tune BERT for classification
  - Build question-answering system
- **Resources**: Create `transformers/` package as you work through the material
- **Key Libraries**: Transformers, Hugging Face

### Month 4: Large Language Models
**Weeks 13-16: LLMs & Generative AI**

#### Week 13: GPT and Language Generation
- **Topics**: GPT architecture, autoregressive generation, prompting
- **Projects**:
  - Fine-tune GPT model
  - Build chatbot system
- **Resources**: Create `gpt/` package as you work through the material

#### Week 14: Advanced LLM Techniques
- **Topics**: RLHF, instruction tuning, few-shot learning
- **Projects**:
  - Implement RLHF pipeline
  - Build instruction-following model
- **Resources**: Create `advanced_llm/` package as you work through the material

#### Week 15: Multimodal Models
- **Topics**: Vision-language models, CLIP, DALL-E
- **Projects**:
  - Build image captioning system
  - Implement CLIP-like model
- **Resources**: Create `multimodal/` package as you work through the material

#### Week 16: LLM Applications & Deployment
- **Topics**: RAG, fine-tuning, model serving
- **Projects**:
  - Build RAG system
  - Deploy LLM application
- **Resources**: Create `llm_deployment/` package as you work through the material
- **Key Libraries**: LangChain, FastAPI

### Month 5: Advanced Topics
**Weeks 17-20: Cutting-Edge AI**

#### Week 17: Reinforcement Learning
- **Topics**: Q-learning, policy gradients, PPO
- **Projects**:
  - Train RL agent for games
  - Implement PPO algorithm
- **Resources**: Create `reinforcement_learning/` package as you work through the material
- **Key Libraries**: Gymnasium, Stable-Baselines3

#### Week 18: Graph Neural Networks
- **Topics**: GNNs, graph convolutions, graph attention
- **Projects**:
  - Build recommendation system with GNNs
  - Graph classification tasks
- **Resources**: Create `graph_neural_networks/` package as you work through the material
- **Key Libraries**: PyTorch Geometric, DGL

#### Week 19: World Models & Simulation
- **Topics**: World models, neural ODEs, differentiable physics
- **Projects**:
  - Build world model for environment
  - Implement neural ODEs
- **Resources**: Create `world_models/` package as you work through the material

#### Week 20: Quantum Machine Learning
- **Topics**: Quantum circuits, quantum neural networks
- **Projects**:
  - Implement quantum algorithms
  - Quantum machine learning experiments
- **Resources**: Create `quantum_ml/` package as you work through the material
- **Key Libraries**: PennyLane

### Month 6: Specialized Applications & Research
**Weeks 21-24: Advanced Applications**

#### Week 21: Audio & Speech Processing
- **Topics**: Speech recognition, text-to-speech, audio generation
- **Projects**:
  - Build speech recognition system
  - Implement TTS pipeline
- **Resources**: Create `audio_processing/` package as you work through the material
- **Key Libraries**: Librosa, SpeechRecognition

#### Week 22: Time Series & Forecasting
- **Topics**: ARIMA, LSTM for time series, Prophet
- **Projects**:
  - Stock price prediction
  - Weather forecasting
- **Resources**: Create `time_series/` package as you work through the material
- **Key Libraries**: Prophet, Statsmodels

#### Week 23: Model Optimization & Deployment
- **Topics**: Model compression, quantization, MLOps
- **Projects**:
  - Optimize model for production
  - Build MLOps pipeline
- **Resources**: Create `model_optimization/` package as you work through the material

#### Week 24: Capstone Project
- **Topics**: End-to-end AI system
- **Projects**:
  - Build complete AI application
  - Research project or startup idea
- **Resources**: Create `capstone/` package as you work through the material

## üìÅ Project Structure

```
AI-Learning/
‚îú‚îÄ‚îÄ notebooks/        # Jupyter notebooks for experiments
‚îú‚îÄ‚îÄ data/            # Datasets
‚îÇ   ‚îú‚îÄ‚îÄ raw/         # Raw data
‚îÇ   ‚îî‚îÄ‚îÄ processed/   # Processed data
‚îú‚îÄ‚îÄ models/          # Saved models
‚îÇ   ‚îú‚îÄ‚îÄ saved/       # Final models
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/ # Training checkpoints
‚îú‚îÄ‚îÄ utils/           # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ data/        # Data processing utilities
‚îÇ   ‚îú‚îÄ‚îÄ visualization/ # Plotting utilities
‚îÇ   ‚îî‚îÄ‚îÄ training/    # Training utilities
‚îú‚îÄ‚îÄ configs/         # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ models/      # Model configurations
‚îÇ   ‚îú‚îÄ‚îÄ training/    # Training configurations
‚îÇ   ‚îî‚îÄ‚îÄ data/        # Data configurations
‚îú‚îÄ‚îÄ experiments/     # Experiment tracking
‚îÇ   ‚îú‚îÄ‚îÄ logs/        # Training logs
‚îÇ   ‚îú‚îÄ‚îÄ results/     # Experiment results
‚îÇ   ‚îî‚îÄ‚îÄ plots/       # Generated plots
‚îú‚îÄ‚îÄ requirements.txt # Python dependencies
‚îî‚îÄ‚îÄ README.md        # This file
```

**Note**: You'll create topic-specific packages as you progress through the course (e.g., `linear_algebra/`, `neural_networks/`, `transformers/`, `llms/`, etc.)

## üõ†Ô∏è Key Libraries & Tools

### Core ML Libraries
- **NumPy**: Numerical computing
- **Pandas**: Data manipulation
- **Scikit-learn**: Traditional ML algorithms
- **SciPy**: Scientific computing

### Deep Learning Frameworks
- **PyTorch**: Primary deep learning framework
- **TensorFlow/Keras**: Alternative deep learning framework
- **Transformers**: Hugging Face transformers library

### Computer Vision
- **OpenCV**: Computer vision operations
- **Albumentations**: Data augmentation
- **Pillow**: Image processing

### Natural Language Processing
- **Transformers**: State-of-the-art NLP models
- **Datasets**: Hugging Face datasets
- **LangChain**: LLM application framework

### Visualization & Analysis
- **Matplotlib**: Basic plotting
- **Seaborn**: Statistical visualization
- **Plotly**: Interactive plots
- **Bokeh**: Interactive web visualizations

### Experiment Tracking
- **Weights & Biases**: Experiment tracking
- **MLflow**: Model lifecycle management
- **TensorBoard**: TensorFlow visualization

### Deployment & Serving
- **FastAPI**: API development
- **Streamlit**: Web applications
- **Gradio**: ML model interfaces

## üéØ Learning Objectives

By the end of this program, you will:

1. **Mathematical Foundations**: Master linear algebra, calculus, probability, and statistics
2. **Machine Learning**: Understand and implement traditional ML algorithms
3. **Deep Learning**: Build and train neural networks for various tasks
4. **Computer Vision**: Develop image processing and computer vision applications
5. **Natural Language Processing**: Work with text data and language models
6. **Large Language Models**: Understand, fine-tune, and deploy LLMs
7. **Advanced Topics**: Explore RL, GNNs, world models, and quantum ML
8. **Production Skills**: Deploy and serve AI models in production

## üìñ Resources

### Books
- "Deep Learning" by Ian Goodfellow, Yoshua Bengio, Aaron Courville
- "Pattern Recognition and Machine Learning" by Christopher Bishop
- "The Elements of Statistical Learning" by Hastie, Tibshirani, Friedman

### Online Courses
- CS229: Machine Learning (Stanford)
- CS231n: Convolutional Neural Networks (Stanford)
- CS224n: Natural Language Processing (Stanford)

### Papers & Research
- Attention Is All You Need (Transformer paper)
- BERT: Pre-training of Deep Bidirectional Transformers
- GPT-3: Language Models are Few-Shot Learners

## ü§ù Contributing

This is a personal learning repository. Feel free to:
- Add your own experiments and projects
- Share interesting findings
- Contribute to the learning materials

## üìù License

This project is for educational purposes. Please respect the licenses of the libraries and datasets used.

---

**Happy Learning! üöÄ**

Start with Week 1 and work through each week systematically. Each week builds upon the previous ones, so don't skip ahead!
